{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-22T13:46:29.232947Z",
     "start_time": "2025-11-22T13:46:19.315193Z"
    }
   },
   "source": [
    "# %% [markdown]\n",
    "# # Fine-tuning 2D U-Net for Tooth Segmentation\n",
    "#\n",
    "# This notebook fine-tunes the 2D U-Net that was pretrained with a\n",
    "# Masked Image Modeling (MIM) reconstruction objective on all 2D\n",
    "# X-ray images (see `pretrain_MIM.ipynb`).\n",
    "#\n",
    "# Pipeline:\n",
    "# 1. Load the index (`sts2d_index.csv`) and reconstruct `df_seg`:\n",
    "#      - 900 image–mask pairs for segmentation.\n",
    "# 2. Build train/val/test splits for segmentation.\n",
    "# 3. Define segmentation transforms and `DentalSegmentationDataset`.\n",
    "# 4. Define 2D U-Net (same as in pretraining).\n",
    "# 5. Load MIM-pretrained weights (except the final output layer).\n",
    "# 6. Define loss (BCE + Dice) and metrics (Dice, IoU).\n",
    "# 7. Fine-tune the model on segmentation data.\n",
    "# 8. Optionally compare with training from scratch by turning off\n",
    "#    the `USE_PRETRAINED` flag.\n",
    "\n",
    "# %% \n",
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib inline  # uncomment in Jupyter if needed\n",
    "\n",
    "# -----------------------------\n",
    "# Reproducibility\n",
    "# -----------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# -----------------------------\n",
    "# Paths (aligned with previous notebooks)\n",
    "# -----------------------------\n",
    "DATA_ROOT = Path(\"./sts_tooth_data\").resolve()\n",
    "PROCESSED_2D_DIR = DATA_ROOT / \"processed_2d\"\n",
    "INDEX_CSV = DATA_ROOT / \"sts2d_index.csv\"\n",
    "CHECKPOINT_DIR = DATA_ROOT / \"checkpoints\"\n",
    "\n",
    "print(\"DATA_ROOT      :\", DATA_ROOT)\n",
    "print(\"PROCESSED_2D   :\", PROCESSED_2D_DIR)\n",
    "print(\"INDEX_CSV path :\", INDEX_CSV)\n",
    "print(\"CHECKPOINT_DIR :\", CHECKPOINT_DIR)\n",
    "\n",
    "# -----------------------------\n",
    "# Device\n",
    "# -----------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Tool\\Anaconda3\\envs\\dlcv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_ROOT      : E:\\Data\\ToothSeg\\sts_tooth_data\n",
      "PROCESSED_2D   : E:\\Data\\ToothSeg\\sts_tooth_data\\processed_2d\n",
      "INDEX_CSV path : E:\\Data\\ToothSeg\\sts_tooth_data\\sts2d_index.csv\n",
      "CHECKPOINT_DIR : E:\\Data\\ToothSeg\\sts_tooth_data\\checkpoints\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T13:47:14.553327Z",
     "start_time": "2025-11-22T13:47:14.515284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %% [markdown]\n",
    "# ## 1. Build `df_seg` (image–mask pairs)\n",
    "#\n",
    "# The index `sts2d_index.csv` has columns:\n",
    "# - rel_path\n",
    "# - age_group\n",
    "# - label_status\n",
    "# - is_mask\n",
    "# - pair_id\n",
    "#\n",
    "# We will:\n",
    "# - separate image rows (is_mask == False) and mask rows (is_mask == True),\n",
    "# - inner-join them on `pair_id` to obtain only pairs that have both image and mask:\n",
    "#     -> `df_seg` with ~900 rows.\n",
    "# %%\n",
    "assert INDEX_CSV.exists(), f\"Index CSV not found: {INDEX_CSV}\"\n",
    "\n",
    "df = pd.read_csv(INDEX_CSV)\n",
    "print(\"Full index shape:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "df_img = df[df[\"is_mask\"] == False].copy()\n",
    "df_mask = df[df[\"is_mask\"] == True].copy()\n",
    "\n",
    "print(\"\\nNumber of image rows:\", len(df_img))\n",
    "print(\"Number of mask rows :\", len(df_mask))\n",
    "\n",
    "# Keep only the columns we need from the mask df for joining\n",
    "df_mask_simple = df_mask[[\"pair_id\", \"rel_path\"]].rename(columns={\"rel_path\": \"mask_rel\"})\n",
    "\n",
    "# Inner join on pair_id to obtain only (image, mask) pairs\n",
    "df_seg = pd.merge(df_img, df_mask_simple, on=\"pair_id\", how=\"inner\")\n",
    "\n",
    "print(\"\\nSegmentation dataframe shape:\", df_seg.shape)\n",
    "print(df_seg.head())\n",
    "\n",
    "print(\"\\nValue counts — age_group in df_seg:\")\n",
    "print(df_seg[\"age_group\"].value_counts())\n",
    "\n",
    "print(\"\\nValue counts — label_status in df_seg:\")\n",
    "print(df_seg[\"label_status\"].value_counts())"
   ],
   "id": "1ffffed0a61ee26d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full index shape: (4900, 5)\n",
      "                          rel_path age_group label_status  is_mask  pair_id\n",
      "0  A-PXI/Labeled/Image/A_L_001.png     adult      labeled    False  a_l_001\n",
      "1  A-PXI/Labeled/Image/A_L_002.png     adult      labeled    False  a_l_002\n",
      "2  A-PXI/Labeled/Image/A_L_003.png     adult      labeled    False  a_l_003\n",
      "3  A-PXI/Labeled/Image/A_L_004.png     adult      labeled    False  a_l_004\n",
      "4  A-PXI/Labeled/Image/A_L_005.png     adult      labeled    False  a_l_005\n",
      "\n",
      "Number of image rows: 4000\n",
      "Number of mask rows : 900\n",
      "\n",
      "Segmentation dataframe shape: (900, 6)\n",
      "                          rel_path age_group label_status  is_mask  pair_id  \\\n",
      "0  A-PXI/Labeled/Image/A_L_001.png     adult      labeled    False  a_l_001   \n",
      "1  A-PXI/Labeled/Image/A_L_002.png     adult      labeled    False  a_l_002   \n",
      "2  A-PXI/Labeled/Image/A_L_003.png     adult      labeled    False  a_l_003   \n",
      "3  A-PXI/Labeled/Image/A_L_004.png     adult      labeled    False  a_l_004   \n",
      "4  A-PXI/Labeled/Image/A_L_005.png     adult      labeled    False  a_l_005   \n",
      "\n",
      "                         mask_rel  \n",
      "0  A-PXI/Labeled/Mask/A_L_001.png  \n",
      "1  A-PXI/Labeled/Mask/A_L_002.png  \n",
      "2  A-PXI/Labeled/Mask/A_L_003.png  \n",
      "3  A-PXI/Labeled/Mask/A_L_004.png  \n",
      "4  A-PXI/Labeled/Mask/A_L_005.png  \n",
      "\n",
      "Value counts — age_group in df_seg:\n",
      "age_group\n",
      "adult       850\n",
      "children     50\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts — label_status in df_seg:\n",
      "label_status\n",
      "labeled    900\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T13:47:54.312802Z",
     "start_time": "2025-11-22T13:47:54.307623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ## 2. Train/val/test split\n",
    "#\n",
    "# We will:\n",
    "# - Shuffle `df_seg`,\n",
    "# - Split into:\n",
    "#     - ~70% train\n",
    "#     - ~15% val\n",
    "#     - ~15% test\n",
    "#\n",
    "# For simplicity, we perform a random split without explicit stratification.\n",
    "# (If needed, we could later add stratified splitting based on age_group and label_status.)\n",
    "# %%\n",
    "df_seg_shuffled = df_seg.sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "n_total = len(df_seg_shuffled)\n",
    "n_train = int(0.7 * n_total)\n",
    "n_val = int(0.15 * n_total)\n",
    "n_test = n_total - n_train - n_val\n",
    "\n",
    "df_train = df_seg_shuffled.iloc[:n_train].reset_index(drop=True)\n",
    "df_val   = df_seg_shuffled.iloc[n_train:n_train + n_val].reset_index(drop=True)\n",
    "df_test  = df_seg_shuffled.iloc[n_train + n_val:].reset_index(drop=True)\n",
    "\n",
    "print(f\"Total samples: {n_total}\")\n",
    "print(f\"Train: {len(df_train)}, Val: {len(df_val)}, Test: {len(df_test)}\")"
   ],
   "id": "844aec4056ca60d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 900\n",
      "Train: 630, Val: 135, Test: 135\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dlcv)",
   "language": "python",
   "name": "dlcv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
